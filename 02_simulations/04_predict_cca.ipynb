{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "sns.set_palette(\"colorblind\")\n",
    "\n",
    "from scipy.io import loadmat\n",
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loc = 'data/'\n",
    "result_loc = 'results/'\n",
    "main_results_loc = 'results/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "palette = sns.color_palette(\"Set1\")\n",
    "\n",
    "import matplotlib \n",
    "matplotlib.rc('xtick', labelsize=20) \n",
    "matplotlib.rc('ytick', labelsize=20) \n",
    "plt.rcParams.update({'font.size': 22})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_all = {}\n",
    "\n",
    "for noise_sigma in [0.5, 0.6, 0.7, 0.8]:\n",
    "    mode = 'basic'\n",
    "\n",
    "    list_of_suffixes = ['CCA_HD']\n",
    "   \n",
    "    \n",
    "    n = 100;\n",
    "    p = 200;\n",
    "    q = 200;\n",
    "    d = 5;\n",
    "\n",
    "    i = 0\n",
    "    sparse_mse = {}\n",
    "\n",
    "    for sigma in [noise_sigma]: \n",
    "            for itr in range(1, 51):  \n",
    "\n",
    "                # 1. Load the matrices corresponding to X and Y\n",
    "                data_loaded = loadmat(data_loc + mode + '/' + #str(int(sparsity*100)) + '_' + \n",
    "                                      str(n)+ '_' + str(p) + '_' + str(q) + '_' + str(d) +\n",
    "                                      '_' + str(int(sigma*100)) + '_' + str(itr) + '.mat')\n",
    "\n",
    "\n",
    "                X_train = np.array(data_loaded['X_train'])\n",
    "                X_valid = np.array(data_loaded['X_valid'])\n",
    "                X_test  = np.array(data_loaded['X_test'])\n",
    "\n",
    "                Y_train = np.array(data_loaded['Y_train'])\n",
    "                Y_valid = np.array(data_loaded['Y_valid'])\n",
    "                Y_test  = np.array(data_loaded['Y_test'])\n",
    "        \n",
    "                w_train = np.array(data_loaded['w_train'])\n",
    "                w_valid = np.array(data_loaded['w_valid'])\n",
    "                w_test  = np.array(data_loaded['w_test'])\n",
    "                \n",
    "                # 4. Train the MLP regressor on these concatenated vectors, training on 'train' and tuning on 'valid'\n",
    "                # 5. Run prediction on test set and note the MSE.\n",
    "\n",
    "                regr = MLPRegressor(hidden_layer_sizes=(50), \n",
    "                                    random_state=1, max_iter=1000).fit(X_train.T, w_train)\n",
    "                w_test_pred = regr.predict(X_test.T)\n",
    "#                 curr_mse = (mean_squared_error(w_test, w_test_pred))\n",
    "                curr_mse = 1/w_test.shape[0] * np.sum((w_test[0,:] - w_test_pred)**2)\n",
    "                sparse_mse[i] = [mode, n, p, q, d, sigma, itr, 'Modality 1', curr_mse]\n",
    "                i = i+1\n",
    "\n",
    "                regr = MLPRegressor(hidden_layer_sizes=(50), random_state=1, max_iter=1000).fit(Y_train.T, w_train)\n",
    "                w_test_pred = regr.predict(Y_test.T)\n",
    "#                 curr_mse = (mean_squared_error(w_test, w_test_pred))\n",
    "                curr_mse = 1/w_test.shape[0] * np.sum((w_test[0,:] - w_test_pred)**2)\n",
    "                sparse_mse[i] = [mode, n, p, q, d, sigma, itr, 'Modality 2', curr_mse]\n",
    "                i = i+1\n",
    "\n",
    "                train_concat = np.concatenate((X_train, Y_train), axis=0).T\n",
    "                valid_concat = np.concatenate((X_valid, Y_valid), axis=0).T\n",
    "                test_concat = np.concatenate((X_test, Y_test), axis=0).T\n",
    "\n",
    "                # 4. Train the MLP regressor on these concatenated vectors, training on 'train' and tuning on 'valid'\n",
    "                # 5. Run prediction on test set and note the MSE.\n",
    "\n",
    "                regr = MLPRegressor(hidden_layer_sizes=(100), random_state=1, max_iter=1000).fit(train_concat, w_train)\n",
    "                w_test_pred = regr.predict(test_concat)\n",
    "#                 curr_mse = (mean_squared_error(w_test, w_test_pred))\n",
    "                curr_mse = 1/w_test.shape[0] * np.sum((w_test[0,:] - w_test_pred)**2)\n",
    "                sparse_mse[i] = [mode, n, p, q, d, sigma, itr, 'Concat', curr_mse]\n",
    "                i = i+1\n",
    "\n",
    "                X_train = np.array(data_loaded['X_train'])\n",
    "                X_valid = np.array(data_loaded['X_valid'])\n",
    "                X_test  = np.array(data_loaded['X_test'])\n",
    "\n",
    "                Y_train = np.array(data_loaded['Y_train'])\n",
    "                Y_valid = np.array(data_loaded['Y_valid'])\n",
    "                Y_test  = np.array(data_loaded['Y_test'])\n",
    "                \n",
    "                weights_loaded = loadmat(result_loc + mode + '/' + #str(int(sparsity*100)) + '_' + \n",
    "                                      str(n)+ '_' + str(p) + '_' + str(q) + '_' + str(d) +\n",
    "                                      '_' + str(int(sigma*100)) + '_' + str(itr) + '.mat')\n",
    "                \n",
    "                for suffix in list_of_suffixes:\n",
    "                    U_pred = np.array(weights_loaded['U_' + suffix])\n",
    "                    V_pred = np.array(weights_loaded['V_' + suffix])\n",
    "\n",
    "                    train_gen = U_pred.T.dot(X_train).T\n",
    "                    valid_gen = U_pred.T.dot(X_valid).T\n",
    "                    test_gen = U_pred.T.dot(X_test).T\n",
    "\n",
    "                    train_img = V_pred.T.dot(Y_train).T\n",
    "                    valid_img = V_pred.T.dot(Y_valid).T\n",
    "                    test_img = V_pred.T.dot(Y_test).T\n",
    "\n",
    "                    train_concat = np.concatenate((U_pred.T.dot(X_train), V_pred.T.dot(Y_train)), axis=0).T\n",
    "                    valid_concat = np.concatenate((U_pred.T.dot(X_valid), V_pred.T.dot(Y_valid)), axis=0).T\n",
    "                    test_concat = np.concatenate((U_pred.T.dot(X_test), V_pred.T.dot(Y_test)), axis=0).T\n",
    "\n",
    "                    regr = MLPRegressor(hidden_layer_sizes=(100), random_state=1, max_iter=1000).fit(train_concat, w_train)\n",
    "                    w_test_pred = regr.predict(test_concat)\n",
    "                    curr_mse = 1/w_test.shape[0] * np.sum((w_test[0,:] - w_test_pred)**2)\n",
    "                    sparse_mse[i] = [mode, n, p, q, d, sigma, itr, suffix, curr_mse]\n",
    "                    i = i+1\n",
    "    mse_all[noise_sigma] = sparse_mse"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noise $\\sigma$ & Modality 1 & Modality 2 & Concat & CCA_HD\n",
      "0.50 & 11.525 $\\pm$ 2.55 & 11.713 $\\pm$ 2.75 & 12.148 $\\pm$ 2.76 & 11.472 $\\pm$ 3.03\\\\\n",
      "0.60 & 13.010 $\\pm$ 2.98 & 13.093 $\\pm$ 3.08 & 13.866 $\\pm$ 3.01 & 12.061 $\\pm$ 2.71\\\\\n",
      "0.70 & 13.821 $\\pm$ 3.77 & 13.922 $\\pm$ 3.45 & 14.253 $\\pm$ 3.51 & 12.040 $\\pm$ 3.34\\\\\n",
      "0.80 & 14.815 $\\pm$ 4.02 & 15.160 $\\pm$ 4.25 & 16.061 $\\pm$ 4.29 & 11.992 $\\pm$ 4.00\\\\\n"
     ]
    }
   ],
   "source": [
    "for noise_sigma in  [0.5, 0.6, 0.7, 0.8]:\n",
    "    if noise_sigma == 0.5:\n",
    "        results_df = pd.DataFrame.from_dict(mse_all[noise_sigma], orient='index')\n",
    "        results_df = results_df.rename(columns={0:'simulation',\n",
    "                                   1:'n', \n",
    "                                   2:'p',\n",
    "                                   3:'q',\n",
    "                                   4:'d',\n",
    "                                   5:'sigma',\n",
    "                                   6:'itr',\n",
    "                                   7:'method',\n",
    "                                   8:'mse'})\n",
    "    \n",
    "    else:\n",
    "        temp_df = pd.DataFrame.from_dict(mse_all[noise_sigma], orient='index')\n",
    "        temp_df = temp_df.rename(columns={0:'simulation',\n",
    "                                   1:'n', \n",
    "                                   2:'p',\n",
    "                                   3:'q',\n",
    "                                   4:'d',\n",
    "                                   5:'sigma',\n",
    "                                   6:'itr',\n",
    "                                   7:'method',\n",
    "                                   8:'mse'})\n",
    "        \n",
    "        results_df = pd.concat([results_df, temp_df], axis=0)\n",
    "        \n",
    "unknown_methods = [\"Modality 1\", \"Modality 2\", \"Concat\", \"CCA_HD\"]\n",
    "results_df = results_df[results_df[\"method\"].isin(unknown_methods)]\n",
    "results_df[\"mse\"] = results_df[\"mse\"] #*100\n",
    "\n",
    "print_row = [\"Noise $\\sigma$\"]\n",
    "print_row.extend(unknown_methods)\n",
    "print(\" & \".join(print_row))\n",
    "\n",
    "for noise_sigma in [0.5, 0.6, 0.7, 0.8]:\n",
    "    print_row = [str(\"{:.2f}\".format(noise_sigma))]\n",
    "    for method in unknown_methods:\n",
    "        curr_df = results_df[results_df[\"method\"] == method]\n",
    "        curr_df = curr_df[curr_df[\"sigma\"] == noise_sigma]\n",
    "        print_row.append(str(\"{:.3f}\".format(curr_df['mse'].mean())) + \" $\\pm$ \" + \n",
    "              str(\"{:.2f}\".format(curr_df['mse'].std())))\n",
    "    print(\" & \".join(print_row) + \"\\\\\\\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brcaCCA",
   "language": "python",
   "name": "brcacca"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
